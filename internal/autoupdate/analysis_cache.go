// Package autoupdate provides analysis caching for LLM-generated schemas.
package autoupdate

import (
	"encoding/json"
	"errors"
	"fmt"
	"os"
	"path/filepath"
	"sync"
	"time"
)

// Error variables for analysis cache errors
var (
	// ErrAnalysisCacheCorrupted is returned when the analysis cache file cannot be parsed
	ErrAnalysisCacheCorrupted = errors.New("analysis cache file is corrupted")
	// ErrAnalysisCacheMiss is returned when an analysis cache entry is not found or expired
	ErrAnalysisCacheMiss = errors.New("analysis cache miss")
)

// DefaultAnalysisCacheTTL is the default time-to-live for analysis cache entries (24 hours)
const DefaultAnalysisCacheTTL = 24 * time.Hour

// AnalysisCacheEntry represents a cached LLM analysis result.
// It stores the generated schema, when it was cached, and the source URL.
type AnalysisCacheEntry struct {
	// Schema is the cached PackageConfig generated by LLM analysis
	Schema *PackageConfig `json:"schema"`
	// Timestamp is when this entry was cached
	Timestamp time.Time `json:"timestamp"`
	// URL is the URL that was analyzed to generate this schema
	URL string `json:"url"`
}

// analysisCacheFile represents the JSON structure stored on disk
type analysisCacheFile struct {
	Entries map[string]AnalysisCacheEntry `json:"entries"`
}

// AnalysisCache manages LLM analysis result caching with TTL-based expiration.
// It persists cache entries to disk and supports concurrent access.
// Cache is stored in ~/.config/bentoo/autoupdate/analysis_cache.json
type AnalysisCache struct {
	// Entries holds all cached analysis entries, keyed by package name
	Entries map[string]AnalysisCacheEntry `json:"entries"`
	// TTL is the time-to-live for cache entries (default: 24 hours)
	TTL time.Duration
	// path is the file path where cache is persisted
	path string
	// mu protects concurrent access to Entries
	mu sync.RWMutex
	// nowFunc allows injecting time for testing
	nowFunc func() time.Time
}

// AnalysisCacheOption is a functional option for configuring AnalysisCache
type AnalysisCacheOption func(*AnalysisCache)

// WithAnalysisCacheTTL sets a custom TTL for the analysis cache
func WithAnalysisCacheTTL(ttl time.Duration) AnalysisCacheOption {
	return func(c *AnalysisCache) {
		c.TTL = ttl
	}
}

// WithAnalysisCacheNowFunc sets a custom time function for testing
func WithAnalysisCacheNowFunc(fn func() time.Time) AnalysisCacheOption {
	return func(c *AnalysisCache) {
		c.nowFunc = fn
	}
}

// NewAnalysisCache creates or loads an analysis cache from disk.
// If the cache file exists, it loads existing entries.
// If the cache file doesn't exist or is corrupted, it creates a new empty cache.
// The configDir should be the bentoo config directory (e.g., ~/.config/bentoo/autoupdate).
func NewAnalysisCache(configDir string, opts ...AnalysisCacheOption) (*AnalysisCache, error) {
	// Ensure config directory exists
	if err := os.MkdirAll(configDir, 0755); err != nil {
		return nil, fmt.Errorf("failed to create analysis cache directory: %w", err)
	}

	cachePath := filepath.Join(configDir, "analysis_cache.json")

	cache := &AnalysisCache{
		Entries: make(map[string]AnalysisCacheEntry),
		TTL:     DefaultAnalysisCacheTTL,
		path:    cachePath,
		nowFunc: time.Now,
	}

	// Apply options
	for _, opt := range opts {
		opt(cache)
	}

	// Try to load existing cache
	if err := cache.load(); err != nil {
		// If file doesn't exist, that's fine - start with empty cache
		if !os.IsNotExist(err) {
			// Log corruption but continue with empty cache
			// The corrupted file will be overwritten on next Save
			cache.Entries = make(map[string]AnalysisCacheEntry)
		}
	}

	return cache, nil
}

// load reads the analysis cache from disk
func (c *AnalysisCache) load() error {
	data, err := os.ReadFile(c.path)
	if err != nil {
		return err
	}

	var cf analysisCacheFile
	if err := json.Unmarshal(data, &cf); err != nil {
		return fmt.Errorf("%w: %v", ErrAnalysisCacheCorrupted, err)
	}

	if cf.Entries != nil {
		c.Entries = cf.Entries
	}

	return nil
}

// Get retrieves a cached schema if it exists and is not expired.
// Returns the schema and true if found and valid, nil and false otherwise.
func (c *AnalysisCache) Get(pkg string) (*PackageConfig, bool) {
	c.mu.RLock()
	defer c.mu.RUnlock()

	entry, exists := c.Entries[pkg]
	if !exists {
		return nil, false
	}

	// Check if entry is expired
	if c.isExpired(entry) {
		return nil, false
	}

	return entry.Schema, true
}

// isExpired checks if an analysis cache entry has expired based on TTL
func (c *AnalysisCache) isExpired(entry AnalysisCacheEntry) bool {
	now := c.nowFunc()
	age := now.Sub(entry.Timestamp)
	return age >= c.TTL
}

// Set stores a schema in the analysis cache with the current timestamp.
// It automatically saves the cache to disk after setting.
func (c *AnalysisCache) Set(pkg string, schema *PackageConfig, url string) error {
	c.mu.Lock()
	defer c.mu.Unlock()

	c.Entries[pkg] = AnalysisCacheEntry{
		Schema:    schema,
		Timestamp: c.nowFunc(),
		URL:       url,
	}

	return c.saveUnsafe()
}

// Save persists the analysis cache to disk.
// This is thread-safe and can be called concurrently.
func (c *AnalysisCache) Save() error {
	c.mu.Lock()
	defer c.mu.Unlock()
	return c.saveUnsafe()
}

// saveUnsafe persists the analysis cache to disk without locking.
// Caller must hold the write lock.
func (c *AnalysisCache) saveUnsafe() error {
	cf := analysisCacheFile{
		Entries: c.Entries,
	}

	data, err := json.MarshalIndent(cf, "", "  ")
	if err != nil {
		return fmt.Errorf("failed to marshal analysis cache: %w", err)
	}

	// Write to temp file first, then rename for atomicity
	tmpPath := c.path + ".tmp"
	if err := os.WriteFile(tmpPath, data, 0644); err != nil {
		return fmt.Errorf("failed to write analysis cache file: %w", err)
	}

	if err := os.Rename(tmpPath, c.path); err != nil {
		// Clean up temp file on rename failure
		os.Remove(tmpPath)
		return fmt.Errorf("failed to rename analysis cache file: %w", err)
	}

	return nil
}

// Delete removes a package from the analysis cache.
// It automatically saves the cache to disk after deletion.
func (c *AnalysisCache) Delete(pkg string) error {
	c.mu.Lock()
	defer c.mu.Unlock()

	delete(c.Entries, pkg)
	return c.saveUnsafe()
}

// Clear removes all entries from the analysis cache.
// It automatically saves the cache to disk after clearing.
func (c *AnalysisCache) Clear() error {
	c.mu.Lock()
	defer c.mu.Unlock()

	c.Entries = make(map[string]AnalysisCacheEntry)
	return c.saveUnsafe()
}

// Len returns the number of entries in the analysis cache.
func (c *AnalysisCache) Len() int {
	c.mu.RLock()
	defer c.mu.RUnlock()
	return len(c.Entries)
}

// GetEntry retrieves the full analysis cache entry for a package.
// Returns the entry and true if found, zero value and false otherwise.
// This does not check TTL - use Get for TTL-aware retrieval.
func (c *AnalysisCache) GetEntry(pkg string) (AnalysisCacheEntry, bool) {
	c.mu.RLock()
	defer c.mu.RUnlock()

	entry, exists := c.Entries[pkg]
	return entry, exists
}

// Cleanup removes all expired entries from the analysis cache.
// It automatically saves the cache to disk after cleanup.
func (c *AnalysisCache) Cleanup() error {
	c.mu.Lock()
	defer c.mu.Unlock()

	for pkg, entry := range c.Entries {
		if c.isExpired(entry) {
			delete(c.Entries, pkg)
		}
	}

	return c.saveUnsafe()
}

// GetWithBypass retrieves a cached schema, optionally bypassing the cache.
// If bypass is true (--no-cache flag), always returns cache miss.
// Returns the schema and true if found and valid (and not bypassed), nil and false otherwise.
func (c *AnalysisCache) GetWithBypass(pkg string, bypass bool) (*PackageConfig, bool) {
	if bypass {
		return nil, false
	}
	return c.Get(pkg)
}
